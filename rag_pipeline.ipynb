{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c201fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'metrics3_utilities' from 'c:\\\\Users\\\\FernandoMaldondoTheD\\\\FernandoGit\\\\rag-fernando-testing\\\\metrics3_utilities.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Project modules ---\n",
    "import metrics3_utilities as m3\n",
    "import kadoa_functions as kadoa\n",
    "import esg_ai_pipeline_functions as esg\n",
    "\n",
    "# --- Environment / config ---\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Standard library ---\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import traceback\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --- Third-party libraries ---\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from flask import request, jsonify, Blueprint\n",
    "from pypdf import PdfReader\n",
    "import tiktoken\n",
    "\n",
    "# --- AI clients ---\n",
    "from openai import OpenAI\n",
    "\n",
    "# Gemini SDKs (keep both â€” pipeline uses google.generativeai)\n",
    "from google import genai          # new SDK (unused but harmless)\n",
    "from google.genai import types    # new SDK types (unused but harmless)\n",
    "#import google.generativeai as genai  # OLD SDK used by pipeline\n",
    "\n",
    "# --- Hot reload for notebook dev ---\n",
    "import importlib\n",
    "importlib.reload(esg)\n",
    "importlib.reload(kadoa)\n",
    "importlib.reload(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fad510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the functions you will need are in the esg_ai_pipeline_functions.py file. \n",
    "# if you need to add a new function, do NOT add it to the esg_ai_pipeline_functions.py file. Instead, please create a new file and label it as \"new_functions.py\" or something clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d937ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE SET UP \n",
    "\n",
    "# Connect to RDS for questions\n",
    "#conn = m3.rds_start_connection(\"dev\", secrets = None)\n",
    "\n",
    "# get all questions from the database. SurveyID 3333 will give you 120 questions, all looking for explicit disclosures. SurveyID 1111 will give you 23 questions, more general in nature. Use 3333 for L3. \n",
    "#questions = esg.rds_get_prompts(conn, survey_id=3333)\n",
    "# print(questions)\n",
    "\n",
    "# the following code lets you pick and choose which questions you want to run. \n",
    "# questions = questions[:5]\n",
    "# pprint(questions)\n",
    "\n",
    "# these are system instructions for the AI. Do NOT change. \n",
    "instructions = esg.instructions\n",
    "# print(instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78355af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read keys from .env\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORG_ID = os.getenv(\"OPENAI_ORG_ID\")\n",
    "OPENAI_PROJECT_ID = os.getenv(\"OPENAI_PROJECT_ID\")\n",
    "\n",
    "# Set the API key for GEMINI\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Set variables for the OpenAI API\n",
    "open_ai_client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    organization=OPENAI_ORG_ID,\n",
    "    project=OPENAI_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23ef395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING LOCAL RAG FOR COMPANY:  test2\n",
      "âœ… Extracted text from cnx.pdf â†’ cnx.txt\n",
      "âœ… Extracted text from iqvia.pdf â†’ iqvia.txt\n",
      "âœ… Extracted text from jet2plc.pdf â†’ jet2plc.txt\n",
      "âœ… Extracted text from mindgym.pdf â†’ mindgym.txt\n",
      "\n",
      "ðŸ“„ Created 4 .txt files in c:\\Users\\FernandoMaldondoTheD\\FernandoGit\\rag-fernando-testing\\Testing Companies\\test2_txt\n"
     ]
    }
   ],
   "source": [
    "###### PROCESS ALL COMPANIES IN \"TESTING COMPANIES\" FOLDER\n",
    "base_path = Path.cwd() / \"Testing Companies\"\n",
    "\n",
    "\n",
    "# use this to do specific companies. \n",
    "do_companies = [\"test2\"]\n",
    "\n",
    "\n",
    "for company in do_companies:\n",
    "    print(\"RUNNING LOCAL RAG FOR COMPANY: \", company)\n",
    "\n",
    "    folder_path = os.path.join(base_path, company)\n",
    "\n",
    "    # if you want to use the chunking and embedding approach, use the following code. if not, comment it out and change use_chunking=False in the function call.\n",
    "\n",
    "    txt_folder = folder_path + \"_txt\"\n",
    "    # Extract text from PDFs and save as .txt files\n",
    "    txt_files = esg.extract_pdfs_to_txt_files(\n",
    "        pdf_folder_path=folder_path,  # Folder containing PDFs\n",
    "        output_folder_path=txt_folder  # If None, saves .txt files in same folder as PDFs\n",
    "    )\n",
    "\n",
    "    if txt_folder:\n",
    "        folder_path = txt_folder\n",
    "    '''\n",
    "    # Then use the txt folder for chunking\n",
    "    esg.ai_run_and_save_scores_locally(\n",
    "        open_ai_client,\n",
    "        genai_client,\n",
    "        folder_path,  # Use the folder with .txt files\n",
    "        company, \n",
    "        instructions,\n",
    "        questions,\n",
    "        use_chunking=True\n",
    "    )\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
